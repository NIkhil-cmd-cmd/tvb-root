{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvb.simulator.models.linear import Linear\n",
    "from tvb.simulator.integrators import HeunStochastic\n",
    "from tvb.simulator.backend.theano import TheanoBackend\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model parameter\n",
    "γ = -0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model instance\n",
    "linear_model = Linear(gamma=np.asarray([γ]))\n",
    "linear_model.configure()\n",
    "\n",
    "# initialize integrator instance\n",
    "integrator = HeunStochastic(dt=0.1)\n",
    "integrator.noise.nsig = np.array([0.001])\n",
    "integrator.noise.configure()\n",
    "integrator.noise.configure_white(dt=integrator.dt)\n",
    "integrator.set_random_state(random_state=None)\n",
    "integrator.configure()\n",
    "integrator.configure_boundaries(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simulation for 1 node\n",
    "simulation_length = 100\n",
    "stimulus = 0.0\n",
    "local_coupling = 0.0\n",
    "current_state = np.random.uniform(low=-1.0, high=1.0, size=[1, 1, 1])\n",
    "state = current_state\n",
    "current_step = 0\n",
    "number_of_nodes = 1\n",
    "start_step = current_step + 1\n",
    "node_coupling = np.zeros([1, 1, 1])\n",
    "n_steps = int(math.ceil(simulation_length / integrator.dt))\n",
    "\n",
    "X = [current_state.copy()]\n",
    "for step in range(start_step, start_step + n_steps):\n",
    "    state = integrator.integrate(state, linear_model, node_coupling, local_coupling, stimulus)\n",
    "    X.append(state.copy())\n",
    "\n",
    "X = np.asarray(X)\n",
    "t = np.linspace(0, simulation_length, n_steps + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(14,8))\n",
    "plt.plot(t, X[:, 0, 0, 0])\n",
    "plt.xlabel(\"time (ms)\")\n",
    "plt.ylabel(\"states\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461beeaf",
   "metadata": {},
   "source": [
    "### Inference using pymc3\n",
    "The inference is done using the probabilistic programming library pymc3. The package provides the implementation of gradient based Bayesian inference methods. Here we use the NUTS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy simulator class for theano backend\n",
    "class sim:\n",
    "    model = linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theano backend template\n",
    "template = \"\"\"\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "import pymc3 as pm \n",
    "<%include file=\"theano-dfuns.py.mako\"/>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pymcInference:\n",
    "    def __init__(self):\n",
    "        # initialize pymc model\n",
    "        self.pymc_model = pm.Model()\n",
    "        with self.pymc_model:\n",
    "            # constant parameters\n",
    "            x0 = X[0]\n",
    "            self.dt = integrator.dt\n",
    "            gfun = integrator.noise.gfun(None)[0]\n",
    "\n",
    "            # inference parameters\n",
    "            # mean and standard deviation of the priors for model parameters are passed as \n",
    "            # a dictionary to the dfun\n",
    "            gamma_star = pm.Normal(name=\"gamma_star\", mu=0.0, sd=1.0)\n",
    "            gamma = pm.Deterministic(name=\"gamma\", var=-0.5 + 0.25 * gamma_star)\n",
    "            self.priors = {\"gamma\": gamma}\n",
    "            # self.priors = {\"gamma\": {\"mu\": -0.5, \"sd\": 0.25}}\n",
    "            \n",
    "            # dynamic noise to fit time series\n",
    "            noise = pm.Normal(name=\"noise\", mu=0.0, sd=1.0, shape=X.shape)\n",
    "            dynamic_noise = pm.Deterministic(name=\"dynamic_noise\", var=gfun * noise)\n",
    "            \n",
    "            # observation noise\n",
    "            BoundedNormal = pm.Bound(pm.Normal, lower=0.0)\n",
    "            obs_noise = BoundedNormal(\"obs_noise\", mu=0.0, sd=1.0)\n",
    "            \n",
    "            # simulate time series using theano scan and theano backend dfun\n",
    "            x_sim, updates = theano.scan(\n",
    "                fn=self.scheme, \n",
    "                sequences=[dynamic_noise], \n",
    "                outputs_info=[x0], \n",
    "                n_steps=X.shape[0]\n",
    "            )\n",
    "\n",
    "            x_obs = pm.Normal(name=\"x_obs\", mu=x_sim, sd=obs_noise, shape=X.shape, observed=X)\n",
    "            \n",
    "    def scheme(self, x_eta, x_prev):\n",
    "        # scheme function builds theano dfun and computes next state\n",
    "        kernel = TheanoBackend().build_py_func(template, dict(sim=sim), \n",
    "                                               name='dfuns', print_source=True)\n",
    "        \n",
    "        dX = tt.zeros(x_prev.shape)\n",
    "        cX = tt.zeros(x_prev.shape)\n",
    "        parmat = sim.model.spatial_parameter_matrix\n",
    "        \n",
    "        dX = kernel(dX, x_prev, cX, parmat, gamma=self.priors[\"gamma\"])\n",
    "        x_next = x_prev + self.dt * dX + x_eta\n",
    "    \n",
    "        return x_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befabd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global inference parameters\n",
    "draws = 250\n",
    "tune = 250\n",
    "cores = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pymcInference instance and run inference\n",
    "pymc_inference = pymcInference()\n",
    "with pymc_inference.pymc_model:\n",
    "    trace = pm.sample(draws=draws, tune=tune, cores=cores, target_accept=0.8)\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace=trace)\n",
    "    inference_data = az.from_pymc3(trace=trace, posterior_predictive=posterior_predictive)\n",
    "    summary = az.summary(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get posterior samples and posterior predicted time series\n",
    "posterior_gamma = inference_data.posterior.gamma.values.reshape((draws + tune,))\n",
    "posterior_obs_noise = inference_data.posterior.obs_noise.values.reshape((draws + tune,))\n",
    "posterior_x_obs = inference_data.posterior_predictive.x_obs.values.reshape((draws + tune, X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axes2 = plt.subplots(ncols=2, nrows=1, figsize=(15,5))\n",
    "axes2[0].hist(posterior_gamma, bins=100);\n",
    "axes2[0].axvline(γ, color=\"r\", label=r\"$\\gamma$\")\n",
    "axes2[0].set_title(\"gamma\")\n",
    "\n",
    "axes2[1].hist(posterior_obs_noise, bins=100);\n",
    "axes2[1].axvline(0.0, color=\"r\", label=r\"observation noise\")\n",
    "axes2[1].set_title(\"observation noise\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(14,8))\n",
    "plt.plot(t, np.percentile(posterior_x_obs, [2.5, 97.5], axis=0).T, \n",
    "         \"k\", label=r\"$X_{pred}^{95\\% PP}(t)$\")\n",
    "plt.plot(t, X[:, 0, 0, 0], label=r\"$X_{obs}$\")\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel(\"time (ms)\")\n",
    "plt.ylabel(\"states\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information criteria\n",
    "waic_criterion = az.waic(inference_data)\n",
    "loo_criterion = az.loo(inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85273fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WAIC: %.2f\" % waic_criterion.waic)\n",
    "print(\"LOO: %.2f\" % loo_criterion.loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "summary.loc[[\"gamma\", \"obs_noise\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "divergent = trace[\"diverging\"]\n",
    "print(\"Number of Divergent: %d\" % divergent.nonzero()[0].size)\n",
    "divperc = divergent.nonzero()[0].size / (cores * len(trace)) * 100\n",
    "print(\"Percentage of Divergent: %.1f\" % divperc)\n",
    "print(\"Mean tree accept: %.1f\" % trace['mean_tree_accept'].mean())\n",
    "print(\"Sampling time in minutes: %.0f\" % (inference_data.sample_stats.sampling_time / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fc823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
